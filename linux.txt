du -h --max-depth=1 /

lsof | grep delete

ps -ef | grep php

kill -9 xxxx

whereis httpd

date

cat /dev/null > /var/log/error_log.log

du -sh /* 2>/dev/null | sort -hr | head -3

yum -y install epel-release

yum clean

yum clean headers

yum clean packages

yum clean oldheaders

网络
mtr vpngate.net

端口检测
netstat -a | egrep 'Proto|LISTEN'

cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 

cat /proc/cpuinfo | grep physical | uniq -c 

cat /proc/meminfo 

cat /proc/version

uname -a

日志切割
usr/local/tomcat/apache-tomcat-7.0.54/logs/catalina.out {

	rotate 31

	daily
	
  copytruncate

	compress

	notifempty

	missingok
	
  dateext

}

mount /dev/xvdb1 /transimg

rotate 31 表示保留31天的备份文件  
daily 表示每天整理一次  
copytruncate 表示先复制log文件的内容，然后再清空  
compress 表示压缩备分文件  
missingok 表示如果找不到log文件也没OK  
notifempty 表示如果log文件是空的，就不进行rotate  
dateext 表示备份的日志文件后缀格式为YYYYMMDD
可以通过/usr/sbin/logrotate -f /etc/logrotate.conf来执行

## 后台运行命令
nohup command {option} > myout.file 2>&1 &?

## 开放端口
netstat -tunlp


#!/bin/ksh
#crontab -e  
#0,5,10,15,20,25,30,40,45,50,55 * * * * /usr/bin/autokill.sh &  #设置为每5分钟检查一次超时进程
#为了安全保险起见,此版脚本的清除范围为:由终端启动的,占用CUP时间超过指定时间长度的,非root用户的进程或僵尸进程  ^_^
 
#检测参数
killlog="/tmp/kill.log"    #默认自动清除超时进程或僵死进程的日志
out=60                     # 默认的超时时间，以秒为单位，默认为60秒，范围为10秒--36000秒
trap 'rm /tmp/kill.tmp 2>/dev/null' 0 1 2 3 9 15
test $LOGNAME != root && { echo "Sorry ! 本 脚 本 只 能 由 root 操 作 !

" ; exit 1 ; }
test "$out" || { echo "
  超时时限不能为空
" ; exit 1 ; }
test "$(echo $out | sed -n '/^[0-9][0-9]*$/p')" || { echo "
  超时时限只能为整数值
" ; exit 1 ; }
test $out -ge 10 -a $out -le 36000 || { echo "
  超时时限范围为10秒--36000秒
" ; exit 1 ; }
 
#查找超时或僵尸进程
ps -efl |awk -v outtest=$out '{ outtime=timetest($14) }
$2~/Z/ || ( $3!~/root/ && $13!~/?/ && outtime=="outtime" ) 
{print $3,$4,$13,$2,$14,$15 }
function timetest(ot)
{
hour=substr(ot,1,2)
min=substr(ot,4,2)
sec=substr(ot,7,8)
if ( hour*3600+min*60+sec > outtest)
return "outtime"
else
return "good" 
} ' >/tmp/kill.tmp 2>/dev/null
 
#保存清除列表
if [ -s /tmp/kill.tmp ]
then
pass=0 
error=0
echo "
清 除 时 间:  "$(date +%y/%m/%d-%H:%M:%S)"
" >> $killlog
awk 'BEGIN{printf("%-8s%-8s%-8s%-7s%-10s%-30s
"),"用户名","进程号","终端号","状态","占用时间","任务名"} 
{ state=statetest($4) ; printf("%-8s%-8s%-8s%-7s%-10s%-30s
"),$1,$2,$3,state,$5,$6} END{print "
"}
function statetest(test)
{  
 if (test=="S") return "睡眠"
 if (test=="R") return "运行"
 if (test=="Z") return "僵尸"
 if (test=="O") return "不存在"
 if (test=="B") return "等待"
 if (test=="T") return "停止"
 if (test=="I") return "中间"
}' /tmp/kill.tmp >> $killlog 2>/dev/null
 
#清除进程
for pid in $(awk '{print $2}' /tmp/kill.tmp |sort -rn) 
do 
kill -9 $pid  
test $? -eq 0 && 
{ echo "自动清除进程 $pid 成功" | awk '{printf("
%-14s%-10s%-4s"),$1,$2,$3}' ; 
echo "自动清除进程 $pid 成功"   | awk '{printf("%-14s%-10s%-4s
"),$1,$2,$3}' 
>> $killlog 2>/dev/null ;  pass=$((pass+1)) ; } || 
{ echo "自动清除进程 $pid 失败" | awk '{printf("
%-14s%-10s%-4s"),$1,$2,$3}' ; 
echo "自动清除进程 $pid 失败"   | awk '{printf("%-14s%-10s%-4s
"),$1,$2,$3}' 
>> $killlog 2>/dev/null ; error=$((error+1)) ; }
done
 
#保存最终统计结果
test $error -eq 0 && 
{ echo "此次共清除 ${pass} 个进程成功" | awk '{printf("

%-14s%-4s%-10s

"),$1,$2,$3}'
  echo "此次共清除 ${pass} 个进程成功" | awk '{printf("
%-14s%-4s%-10s

"),$1,$2,$3}' 
>> $killlog 2>/dev/null ; } || 
{ echo "此次共清除 ${pass} 个进程成功 ${error} 个进程失败" | 
awk '{printf("

%-14s%-4s%-16s%-10s%-10s

"),$1,$2,$3,$4,$5}' ; 
  echo "此次共清除 ${pass} 个进程成功 ${error} 个进程失败" | 
awk '{printf("

%-14s%-4s%-16s%-10s%-10s

"),$1,$2,$3,$4,$5}' >> $killlog 2>/dev/null ; }
fi

iptables -L
iptables -I INPUT -s 183.160.107.239 -p tcp --dport 3306 -j ACCEPT

iptables -I INPUT -s 180.162.0.0/16 -p tcp --dport 3306 -j ACCEPT

iptables -I INPUT -s 36.7.0.0/16 -p tcp --dport 3306 -j ACCEPT

iptables-save

iptables-restore

//####备份同步
yum install xtrabackup

innobackupex --user=root --password=MJsujrctG6pU0OUG --defaults-file=/etc/my.cnf /transimg/back --include=wushi --no-timestamp

--include=navy
--databases=navy

######script.sh
#!/bin/sh
MYSQL="mysql -h123.57.133.51 -uley -pzq1988 --default-character-set=utf8 -A -N"
stime=`date -d "20 day ago" +%s`
sql="SELECT COUNT(*) AS c FROM mycrm.xy_account WHERE style=0 AND ((block=0) or  (block=1 and blocktime>$stime and blocktime is not null))"
# echo $sql
result="$($MYSQL -e "$sql")"
# result=726
pagesize=30
page=$(($result/$pagesize+1))
# echo $page
for((k=1;k<=$page;k++))
do
    MM=`ps -aux |grep "php /data/cron/script2.php $k $pagesize"$ |grep -v "grep" |wc -l`
    if [ "$MM" == "0" ]; then
        echo "$k restart"
        nohup php /data/cron/script2.php $k $pagesize >> /data/cron/script2.log 2>&1 &
    fi
done
MM=`ps -aux |grep "php /data/cron/createsendorder.php" |grep -v "grep" |wc -l`
if [ "$MM" == "0" ]; then
    nohup php /data/cron/createsendorder.php >> /data/cron/createsendorder.log 2>&1 &
fi

###### 清除进程 clear kill
#!/bin/sh
if [ $# -lt 1 ]
then
  echo "缺少参数"
  exit 1
fi

ps -ef|grep $1|grep -v grep|awk '{print $2}'|xargs kill -9


chattr +i /网站目录/.user.ini

//字体
centos
yum install bitmap-fonts bitmap-fonts-cjk
ubuntn
sudo apt-get install xfonts-wqy

//nodejs
yum install epel-release


// ssl 证书

// 生成服务器端私钥
命令：openssl genrsa -out api.transportjp.com.server.key 1024
// 生成服务器端公钥
命令：openssl rsa -in api.transportjp.com.server.key -pubout -out api.transportjp.com.server.pem

// 生成 CA 私钥
命令：openssl genrsa -out api.transportjp.com.ca.key 1024
命令：openssl req -new -key api.transportjp.com.ca.key -out api.transportjp.com.ca.csr
命令：openssl x509 -req -in api.transportjp.com.ca.csr -signkey api.transportjp.com.ca.key -out api.transportjp.com.ca.crt

// 服务器端需要向 CA 机构申请签名证书，在申请签名证书之前依然是创建自己的 CSR 文件
命令：openssl req -new -key api.transportjp.com.server.key -out api.transportjp.com.server.csr
// 向自己的 CA 机构申请证书，签名过程需要 CA 的证书和私钥参与，最终颁发一个带有 CA 签名的证书
命令：openssl x509 -req -CA api.transportjp.com.ca.crt -CAkey api.transportjp.com.ca.key -CAcreateserial -in api.transportjp.com.server.csr -out api.transportjp.com.server.crt

//使用openssl 进行转换
命令：openssl x509 -in api.transportjp.com.server.crt -out api.transportjp.com.server.cer -outform der

//version 2
openssl genrsa -des3 -out dev.apistore.transportjp.com.key 1024
openssl req -new -subj /C=CN/ST=AnHui/L=HeFei/O=iTranswarp/OU=iTranswarp/CN=dev.apistore.transportjp.com -key dev.apistore.transportjp.com.key -out dev.apistore.transportjp.com.csr
mv dev.apistore.transportjp.com.key dev.apistore.transportjp.com.origin.key
openssl rsa -in dev.apistore.transportjp.com.origin.key -out dev.apistore.transportjp.com.key
openssl x509 -req -days 3650 -in dev.apistore.transportjp.com.csr -signkey dev.apistore.transportjp.com.key -out dev.apistore.transportjp.com.crt

<VirtualHost *:443>
   SSLEngine On
   SSLCertificateFile conf/ssl/server.crt
   SSLCertificateKeyFile conf/ssl/server.key
   SSLCertificateChainFile conf/ssl/ca.crt
</VirtualHost>


//阿里云磁盘扩容
//https://help.aliyun.com/document_detail/25452.html?spm=5176.11065259.1996646101.searchclickresult.1db338f2uDGalg

//罗列磁盘
lsblk -f

重启服务器后

umount /dev/xvdb

fdisk -l 罗列分区信息并记录扩容前数据盘的最终容量、起始扇区（First sector）位置

fdisk /dev/xvdb

d 并按回车键，删除原来的分区

n 并按回车键，开始创建新的分区

p 并按回车键，选择创建主分区

1 创建一个分区，所以输入 1

First sector 需要与原来的分区保持一致。在本示例中，按回车键采用默认值

输入最后一个扇区编号：因为这里仅创建一个分区，所以按回车键采用默认值

输入 wq 并按回车键，开始分区

e2fsck -f /dev/xvdb # 检查文件系统
resize2fs /dev/xvdb # 变更文件系统大小

mount /dev/xvdb /transimg

# mount: you must specify the filesystem type
mkfs.ext3 /dev/vdb 格式化

##压缩
tar -cjf *.tar.bz2 要打包的目录或文件

##解压
tar -jxvf xx.tar.bz2
tar zxvf pythontab.tar.gz

memcached -d -p 11211 -u memcached -m 64 -c 1024 -P -U 0 /var/run/memcached/memcached.pid -U 0
memcached -d -m 1024 -u root -l 127.0.0.1 -p 11211 -c 1024 -P /tmp/memcached.pid

###删除指定日期文件
find /path -mtime +30 -type f -name \*.zip -exec rm -f {} \;

###流量查看
iftop -i eth1 -P

[rsync]
-a 参数，相当于-rlptgoD，-r 是递归 -l 是链接文件，意思是拷贝链接文件；-p 表示保持文件原有权限；-t 保持文件原有时间；-g 保持文件原有用户组；-o 保持文件原有属主；-D 相当于块设备文件；
-z 传输时压缩；
-P 传输进度；
-v 传输时的进度等信息，和-P有点关系
rsync -avz --delete --exclude Application/Runtime/ userid@172.16.7.158::mokuai /var/www/html/rigouwang/ --password-file=/etc/rsyncd.pwd
rsync -r 172.16.10.5:/etc /tmp 
rsync -av 源目录 目标目录

[inotifywait] 只要使用inotifywait检测到事件时，自动执行rsync进行同步操作即可。加上执行权限并在后台运行即可
#!/bin/bash
inotifywait -mrq -e create,close_write,move,delete,modify /var/www/html/  | while read a b c
do     
rsync -azP --delete /var/www/html/ root@192.168.94.29:/backup(或者rsync -azp /backup/ rsync_backup@192.168.94.29::backup --password-file=/et
c/rsync.password)

[rsync + inotifywait]
#!/bin/bash
src=/data/                           # 需要同步的源路径
des=data                             # 目标服务器上 rsync --daemon 发布的名称，rsync --daemon这里就不做介绍了，网上搜一下，比较简单。
rsync_passwd_file=/etc/rsyncd.passwd            # rsync验证的密码文件
ip1=192.168.0.18                 # 目标服务器1
ip2=192.168.0.19                 # 目标服务器2
user=root                            # rsync --daemon定义的验证用户名
cd ${src}                              # 此方法中，由于rsync同步的特性，这里必须要先cd到源目录，inotify再监听 ./ 才能rsync同步后目录结构一致，有兴趣的同学可以进行各种尝试观看其效果
/usr/local/bin/inotifywait -mrq --format  '%Xe %w%f' -e modify,create,delete,attrib,close_write,move ./ | while read file         # 把监控到有发生更改的"文件路径列表"循环
do
        INO_EVENT=$(echo $file | awk '{print $1}')      # 把inotify输出切割 把事件类型部分赋值给INO_EVENT
        INO_FILE=$(echo $file | awk '{print $2}')       # 把inotify输出切割 把文件路径部分赋值给INO_FILE
        echo "-------------------------------$(date)------------------------------------"
        echo $file
        #增加、修改、写入完成、移动进事件
        #增、改放在同一个判断，因为他们都肯定是针对文件的操作，即使是新建目录，要同步的也只是一个空目录，不会影响速度。
        if [[ $INO_EVENT =~ 'CREATE' ]] || [[ $INO_EVENT =~ 'MODIFY' ]] || [[ $INO_EVENT =~ 'CLOSE_WRITE' ]] || [[ $INO_EVENT =~ 'MOVED_TO' ]]         # 判断事件类型
        then
                echo 'CREATE or MODIFY or CLOSE_WRITE or MOVED_TO'
                rsync -avzcR --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip1}::${des} &amp;&amp;         # INO_FILE变量代表路径哦  -c校验文件内容
                rsync -avzcR --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip2}::${des}
                 #仔细看 上面的rsync同步命令 源是用了$(dirname ${INO_FILE})变量 即每次只针对性的同步发生改变的文件的目录(只同步目标文件的方法在生产环境的某些极端环境下会漏文件 现在可以在不漏文件下也有不错的速度 做到平衡) 然后用-R参数把源的目录结构递归到目标后面 保证目录结构一致性
        fi
        #删除、移动出事件
        if [[ $INO_EVENT =~ 'DELETE' ]] || [[ $INO_EVENT =~ 'MOVED_FROM' ]]
        then
                echo 'DELETE or MOVED_FROM'
                rsync -avzR --delete --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip1}::${des} &amp;&amp;
                rsync -avzR --delete --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip2}::${des}
                #看rsync命令 如果直接同步已删除的路径${INO_FILE}会报no such or directory错误 所以这里同步的源是被删文件或目录的上一级路径，并加上--delete来删除目标上有而源中没有的文件，这里不能做到指定文件删除，如果删除的路径越靠近根，则同步的目录月多，同步删除的操作就越花时间。这里有更好方法的同学，欢迎交流。
        fi
        #修改属性事件 指 touch chgrp chmod chown等操作
        if [[ $INO_EVENT =~ 'ATTRIB' ]]
        then
                echo 'ATTRIB'
                if [ ! -d "$INO_FILE" ]                 # 如果修改属性的是目录 则不同步，因为同步目录会发生递归扫描，等此目录下的文件发生同步时，rsync会顺带更新此目录。
                then
                        rsync -avzcR --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip1}::${des} &amp;&amp;            
                        rsync -avzcR --password-file=${rsync_passwd_file} $(dirname ${INO_FILE}) ${user}@${ip2}::${des}
                fi
        fi
done

crontab -e
* */2 * * * rsync -avz --password-file=/etc/rsync-client.pass /data/ root@192.168.0.18::data && rsync -avz --password-file=/etc/rsync-client.pass /data/ root@192.168.0.19::data


[scp]
scp work@192.168.0.10:/home/work/source.txt /home/work/

###php 安装
ln -s /usr/lib64/libc-client.so /usr/lib/libc-client.so

[https]
wget https://dl.eff.org/certbot-auto
chmod a+x certbot-auto
certbot-auto certonly --text --agree-tos --webroot -w /transimg/www/transportjp -d style.transportjp.com

[extundelete] 文件恢复工具
extundelete /dev/vdb --inode 2

ls -id 查看node

[shell]
path=$(cd `dirname $0`; pwd)
nohup mysql -uroot -pMJsujrctG6pU0OUG -h172.24.63.203 < $path/tao86_f_opij.sql 2>&1 &
